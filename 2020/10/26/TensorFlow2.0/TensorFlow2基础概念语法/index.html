<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/xiaohong404.github.io/images/logo.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/xiaohong404.github.io/images/logo.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/xiaohong404.github.io/images/logo.png">
  <link rel="mask-icon" href="/xiaohong404.github.io/images/logo.png" color="#222">

<link rel="stylesheet" href="/xiaohong404.github.io/css/main.css">


<link rel="stylesheet" href="/xiaohong404.github.io/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"github.com","root":"/xiaohong404.github.io/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow2基础概念语法">
<meta property="og:url" content="https://github.com/xiaohong404/xiaohong404.github.io/2020/10/26/TensorFlow2.0/TensorFlow2%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E8%AF%AD%E6%B3%95/index.html">
<meta property="og:site_name" content="Mr.red">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://github.com/xiaohong404.github.io/2020/10/26/TensorFlow2.0/TensorFlow2%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E8%AF%AD%E6%B3%95/0.png">
<meta property="og:image" content="https://github.com/xiaohong404.github.io/2020/10/26/TensorFlow2.0/TensorFlow2%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E8%AF%AD%E6%B3%95/1.png">
<meta property="article:published_time" content="2020-10-26T09:41:24.000Z">
<meta property="article:modified_time" content="2020-10-26T10:20:26.000Z">
<meta property="article:author" content="Xiao Hong">
<meta property="article:tag" content="TensorFlow2.0">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/xiaohong404.github.io/2020/10/26/TensorFlow2.0/TensorFlow2%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E8%AF%AD%E6%B3%95/0.png">

<link rel="canonical" href="https://github.com/xiaohong404/xiaohong404.github.io/2020/10/26/TensorFlow2.0/TensorFlow2%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E8%AF%AD%E6%B3%95/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>TensorFlow2基础概念语法 | Mr.red</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/xiaohong404.github.io/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Mr.red</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/xiaohong404.github.io/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/xiaohong404.github.io/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/xiaohong404.github.io/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/xiaohong404.github.io/Categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/xiaohong404.github.io/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://github.com/xiaohong404/xiaohong404.github.io/2020/10/26/TensorFlow2.0/TensorFlow2%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E8%AF%AD%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/69063618?s=460&u=11199d69e5551ba91c0709fae0a30a592ab1271b&v=4">
      <meta itemprop="name" content="Xiao Hong">
      <meta itemprop="description" content="Things always start to get better after you give up">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mr.red">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          TensorFlow2基础概念语法
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-10-26 17:41:24 / Modified: 18:20:26" itemprop="dateCreated datePublished" datetime="2020-10-26T17:41:24+08:00">2020-10-26</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/xiaohong404.github.io/Categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/xiaohong404.github.io/Categories/Machine-Learning/TensorFlow/" itemprop="url" rel="index"><span itemprop="name">TensorFlow</span></a>
                </span>
            </span>

          
            <span id="/xiaohong404.github.io/2020/10/26/TensorFlow2.0/TensorFlow2%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E8%AF%AD%E6%B3%95/" class="post-meta-item leancloud_visitors" data-flag-title="TensorFlow2基础概念语法" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/xiaohong404.github.io/2020/10/26/TensorFlow2.0/TensorFlow2%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E8%AF%AD%E6%B3%95/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/xiaohong404.github.io/2020/10/26/TensorFlow2.0/TensorFlow2%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E8%AF%AD%E6%B3%95/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><strong><img src="/xiaohong404.github.io/2020/10/26/TensorFlow2.0/TensorFlow2%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E8%AF%AD%E6%B3%95/0.png" class></strong></p>
 <a id="more"></a>

<h2 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h2><p>数学或物理上关于张量的两种定义方法（抽象）：</p>
<ul>
<li>通常定义张量的物理学或传统数学方法，是把张量看成一个多维数组，当变换坐标或变换基底时，其分量会按照一定规则进行变换，这些规则有两种：即协变或逆变转换。</li>
<li>通常现代数学中的方法，是把张量定义成某个矢量空间或其对偶空间上的多重线性映射，这矢量空间在需要引入基底之前不固定任何坐标系统。例如协变矢量，可以描述为 1-形式，或者作为逆变矢量的对偶空间的元素。</li>
</ul>
<p>通俗来讲，一阶张量为向量，二阶张量为矩阵。当然，零阶张量也就是标量，而更重要的是 𝑁 阶张量，也就是 𝑁 维数组。</p>
<table>
<thead>
<tr>
<th align="center">阶</th>
<th align="center">数学实例</th>
</tr>
</thead>
<tbody><tr>
<td align="center">0</td>
<td align="center">标量（只有大小）</td>
</tr>
<tr>
<td align="center">1</td>
<td align="center">矢量（大小和方向）</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">矩阵（数据表）</td>
</tr>
<tr>
<td align="center">3</td>
<td align="center">3 阶张量（数据立体）</td>
</tr>
<tr>
<td align="center">N</td>
<td align="center">N 阶张量（自行想象）</td>
</tr>
</tbody></table>
<p><strong><img src="/xiaohong404.github.io/2020/10/26/TensorFlow2.0/TensorFlow2%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E8%AF%AD%E6%B3%95/1.png" class></strong></p>
<p>大多数深度学习框架都会使用张量的概念，这样做的好处是统一对数据的定义。NumPy 中，数据都使用 Ndarray 多维数组进行定义，TensorFlow 中，数据都会用张量进行表述。</p>
<p>下面就来学习 TensorFlow 中对张量的定义。在 TensorFlow 中，每一个 Tensor 都具备两个基础属性：<strong>数据类型（默认：float32）和形状</strong>。</p>
<p>其中，数据类型大致如下表所示：</p>
<table>
<thead>
<tr>
<th align="center">Tensor 类型</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>tf.float32</code></td>
<td align="center">32 位浮点数</td>
</tr>
<tr>
<td align="center"><code>tf.float64</code></td>
<td align="center">64 位浮点数</td>
</tr>
<tr>
<td align="center"><code>tf.int64</code></td>
<td align="center">64 位有符号整型</td>
</tr>
<tr>
<td align="center"><code>tf.int32</code></td>
<td align="center">32 位有符号整型</td>
</tr>
<tr>
<td align="center"><code>tf.int16</code></td>
<td align="center">16 位有符号整型</td>
</tr>
<tr>
<td align="center"><code>tf.int8</code></td>
<td align="center">8 位有符号整型</td>
</tr>
<tr>
<td align="center"><code>tf.uint8</code></td>
<td align="center">8 位无符号整型</td>
</tr>
<tr>
<td align="center"><code>tf.string</code></td>
<td align="center">可变长度的字节数组</td>
</tr>
<tr>
<td align="center"><code>tf.bool</code></td>
<td align="center">布尔型</td>
</tr>
<tr>
<td align="center"><code>tf.complex64</code></td>
<td align="center">实数和虚数</td>
</tr>
</tbody></table>
<p>另外，TensorFlow 通过三种符号约定来描述张量维度：<strong>阶，形状和维数</strong>。三者之间的关系如下：</p>
<table>
<thead>
<tr>
<th align="center">形状</th>
<th align="center">阶</th>
<th align="center">维数</th>
<th align="center">示例</th>
</tr>
</thead>
<tbody><tr>
<td align="center">[]</td>
<td align="center">0</td>
<td align="center">0-D</td>
<td align="center">0 维张量，标量。</td>
</tr>
<tr>
<td align="center">[D0]</td>
<td align="center">1</td>
<td align="center">1-D</td>
<td align="center">形状为 [5] 的 1 维张量。</td>
</tr>
<tr>
<td align="center">[D0, D1]</td>
<td align="center">2</td>
<td align="center">2-D</td>
<td align="center">形状为 [3, 4] 的 2 维张量。</td>
</tr>
<tr>
<td align="center">[D0, D1, D2]</td>
<td align="center">3</td>
<td align="center">3-D</td>
<td align="center">形状为 [1, 4, 3] 的 3 维张量。</td>
</tr>
<tr>
<td align="center">[D0, D1, … Dn-1]</td>
<td align="center">n</td>
<td align="center">n-D</td>
<td align="center">形状为 [D0, D1, … Dn-1] 的张量。</td>
</tr>
</tbody></table>
<p>值得注意的是，上表中的示例都是形容张量的形状。例如 <code>[3, 4]</code> 指的张量的形状为 <code>[3, 4]</code>，而不是张量 <code>[3, 4]</code>。</p>
<p> 根据不同的用途，TensorFlow 中主要有 2 种张量类型，分别是：</p>
<ul>
<li><p><code>tf.Variable</code> ：变量 Tensor，需要指定初始值，常用于定义可变参数，例如神经网络的权重。</p>
</li>
<li><p><code>tf.constant</code> ：常量 Tensor，需要指定初始值，定义不变化的张量。</p>
</li>
</ul>
<p>我们可以通过传入列表或 NumPy 数组来新建变量和常量类型的张量：</p>
<p>查看tensorflow版本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.__version__</span><br><span class="line"></span><br><span class="line">Out:  <span class="string">&#x27;2.1.0&#x27;</span></span><br></pre></td></tr></table></figure>

<p>  输入形状为 (2, 2) 的二维变量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">v = tf.Variable([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])  <span class="comment"># 形状为 (2, 2) 的二维变量</span></span><br><span class="line">v</span><br><span class="line"></span><br><span class="line">Out:  &lt;tf.Variable <span class="string">&#x27;Variable:0&#x27;</span> shape=(<span class="number">2</span>, <span class="number">2</span>) dtype=int32, numpy=</span><br><span class="line">		array([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">      		   [<span class="number">3</span>, <span class="number">4</span>]], dtype=int32)&gt;</span><br></pre></td></tr></table></figure>

<p>  输入形状为 (2, 2) 的二维常量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">c = tf.constant([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])  <span class="comment"># 形状为 (2, 2) 的二维常量</span></span><br><span class="line">c</span><br><span class="line"></span><br><span class="line">Out:  &lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=int32, numpy=</span><br><span class="line">    	 array([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">         	    [<span class="number">3</span>, <span class="number">4</span>]], dtype=int32)&gt;</span><br></pre></td></tr></table></figure>

<p>输出包含了张量的 3 部分属性，分别是形状 <code>shape</code>，数据类型 <code>dtype</code>，以及对应的 NumPy 数组。</p>
<p>还可以直接通过 <code>.numpy()</code> 输出张量的 NumPy 数组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">c.numpy()</span><br><span class="line"></span><br><span class="line">Out:  array([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">             [<span class="number">3</span>, <span class="number">4</span>]], dtype=int32)</span><br></pre></td></tr></table></figure>

<p>下面列举几个经常会用到的新建特殊常量张量的方法：</p>
<ul>
<li><code>tf.zeros</code>：新建指定形状且全为 0 的常量 Tensor</li>
<li><code>tf.zeros_like</code>：参考某种形状，新建全为 0 的常量 Tensor</li>
<li><code>tf.ones</code>：新建指定形状且全为 1 的常量 Tensor</li>
<li><code>tf.ones_like</code>：参考某种形状，新建全为 1 的常量 Tensor</li>
<li><code>tf.fill</code>：新建一个指定形状且全为某个标量值的常量 Tensor</li>
</ul>
<p>3x3 全为 0 的常量 Tensor</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">c = tf.zeros([<span class="number">3</span>, <span class="number">3</span>])  <span class="comment"># 3x3 全为 0 的常量 Tensor</span></span><br><span class="line">c</span><br><span class="line"></span><br><span class="line">Out:  &lt;tf.Tensor: shape=(<span class="number">3</span>, <span class="number">3</span>), dtype=float32, numpy=</span><br><span class="line">        array([[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">               [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">               [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]], dtype=float32)&gt;</span><br></pre></td></tr></table></figure>

<p>与 c 形状一致全为 1 的常量 Tensor</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tf.ones_like(c)  <span class="comment"># 与 c 形状一致全为 1 的常量 Tensor</span></span><br><span class="line"></span><br><span class="line">Out:  &lt;tf.Tensor: shape=(<span class="number">3</span>, <span class="number">3</span>), dtype=float32, numpy=</span><br><span class="line">        array([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">               [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">               [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]], dtype=float32)&gt;</span><br></pre></td></tr></table></figure>

<p>2x3 全为 6 的常量 Tensor</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.fill([<span class="number">2</span>, <span class="number">3</span>], <span class="number">6</span>)  <span class="comment"># 2x3 全为 6 的常量 Tensor</span></span><br><span class="line"></span><br><span class="line">Out:  &lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">3</span>), dtype=int32, numpy=</span><br><span class="line">        array([[<span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>],</span><br><span class="line">               [<span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>]], dtype=int32)&gt;</span><br></pre></td></tr></table></figure>

<p>除此之外，还可以创建一些序列:</p>
<ul>
<li><code>tf.linspace</code>：创建一个等间隔序列。</li>
<li><code>tf.range</code>：创建一个数字序列。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tf.linspace(<span class="number">1.0</span>, <span class="number">10.0</span>, <span class="number">5</span>, name=<span class="string">&quot;linspace&quot;</span>)</span><br><span class="line"></span><br><span class="line">Out:  &lt;tf.Tensor: shape=(<span class="number">5</span>,), dtype=float32, numpy=array([ <span class="number">1.</span>  ,  <span class="number">3.25</span>,  <span class="number">5.5</span> ,  <span class="number">7.75</span>, <span class="number">10.</span>  ],     dtype=float32)&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tf.range(start=<span class="number">1</span>, limit=<span class="number">10</span>, delta=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">Out:  &lt;tf.Tensor: shape=(<span class="number">5</span>,), dtype=int32, numpy=array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>], dtype=int32)&gt;</span><br></pre></td></tr></table></figure>

<h2 id="Eager-Execution"><a href="#Eager-Execution" class="headerlink" title="Eager Execution"></a>Eager Execution</h2><p>TensorFlow 2 带来的最大改变之一是将 1.x 的 Graph Execution（图与会话机制）更改为 Eager Execution（动态图机制）。在 1.x 版本中，低级别 TensorFlow API 首先需要定义数据流图，然后再创建 TensorFlow 会话，这一点在 2.0 中被完全舍弃。TensorFlow 2 中的 Eager Execution 是一种命令式编程环境，可立即评估操作，无需构建图。</p>
<p>所以说，TensorFlow 的张量运算过程可以像 NumPy 一样直观且自然了。接下来，我们以最简单的加法运算为例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">c + c  <span class="comment"># 加法计算</span></span><br><span class="line"></span><br><span class="line">Out:  &lt;tf.Tensor: shape=(<span class="number">3</span>, <span class="number">3</span>), dtype=float32, numpy=</span><br><span class="line">        array([[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">               [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">               [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]], dtype=float32)&gt;</span><br></pre></td></tr></table></figure>

<p> 1.x 版本的 TensorFlow，一个加法运算过程十分复杂。我们需要初始化全局变量 → 建立会话 → 执行计算，最终才能打印出张量的运算结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">init_op = tf.global_variables_initializer()  <span class="comment"># 初始化全局变量</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:  <span class="comment"># 启动会话</span></span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    print(sess.run(c + c))  <span class="comment"># 执行计算</span></span><br></pre></td></tr></table></figure>

<p>Eager Execution 带来的好处显而易见，其进一步降低了 TensorFlow 的入门门槛。之前的 Graph Execution 模式，实际上让很多人在入门时都很郁闷，因为完全不符合正常思维习惯。</p>
<p>TensorFlow 中提供的数学计算，包括线性代数计算方面的方法也是应有尽有，十分丰富。下面，我们再列举几个示例:</p>
<p>矩阵乘法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>], shape=[<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">b = tf.constant([<span class="number">7.</span>, <span class="number">8.</span>, <span class="number">9.</span>, <span class="number">10.</span>, <span class="number">11.</span>, <span class="number">12.</span>], shape=[<span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">c = tf.linalg.matmul(a, b)  <span class="comment"># 矩阵乘法</span></span><br><span class="line">c</span><br><span class="line"></span><br><span class="line">Out:  &lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=float32, numpy=</span><br><span class="line">        array([[ <span class="number">58.</span>,  <span class="number">64.</span>],</span><br><span class="line">               [<span class="number">139.</span>, <span class="number">154.</span>]], dtype=float32)&gt;</span><br></pre></td></tr></table></figure>

<p>转置矩阵：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.linalg.matrix_transpose(c)  <span class="comment"># 转置矩阵</span></span><br><span class="line"></span><br><span class="line">Out:  &lt;tf.Tensor: shape=(<span class="number">2</span>, <span class="number">2</span>), dtype=float32, numpy=</span><br><span class="line">        array([[ <span class="number">58.</span>, <span class="number">139.</span>],</span><br><span class="line">               [ <span class="number">64.</span>, <span class="number">154.</span>]], dtype=float32)&gt;</span><br></pre></td></tr></table></figure>

<p><code>可以把 TensorFlow 理解成为 TensorFlow 式的 NumPy + 为搭建神经网络而生的 API</code></p>
<h2 id="自动微分"><a href="#自动微分" class="headerlink" title="自动微分"></a>自动微分</h2><p>在数学中，微分是对函数的局部变化率的一种线性描述。虽然微分和导数是两个不同的概念。但是，对一元函数来说，可微与可导是完全等价的。如果熟悉神经网络的搭建过程，应该明白梯度的重要性。而对于复杂函数的微分过程是极其麻烦的，为了提高应用效率，大部分深度学习框架都有自动微分机制。</p>
<p>TensorFlow 中，可以使用 <code>tf.GradientTape</code> 跟踪全部运算过程，以便在必要的时候计算梯度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">w = tf.Variable([<span class="number">1.0</span>])  <span class="comment"># 新建张量</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:  <span class="comment"># 追踪梯度</span></span><br><span class="line">    loss = w * w</span><br><span class="line"></span><br><span class="line">grad = tape.gradient(loss, w)  <span class="comment"># 计算梯度</span></span><br><span class="line">grad</span><br><span class="line"></span><br><span class="line">Out:  &lt;tf.Tensor: shape=(<span class="number">1</span>,), dtype=float32, numpy=array([<span class="number">2.</span>], dtype=float32)&gt;</span><br></pre></td></tr></table></figure>

<p>上面演示了一个自动微分过程，它的数学求导过程如下：</p>
<p>$$ loss = w^2 \rightarrow \frac {\partial loss}{\partial w} = 2w $$</p>
<p>所以，当 w 等于 1 时，计算结果为 2。</p>
<p><code>tf.GradientTape</code> 会像磁带一样记录下计算图中的梯度信息，然后使用 <code>.gradient</code> 即可回溯计算出任意梯度，这对于使用 TensorFlow 低阶 API 构建神经网络时更新参数非常重要。</p>
<h2 id="常用模块"><a href="#常用模块" class="headerlink" title="常用模块"></a>常用模块</h2><p>上面已经学习了 TensorFlow 核心知识，接下来将对 TensorFlow API 中的常用模块进行简单的功能介绍。对于框架的使用，实际上就是灵活运用各种封装好的类和函数。由于 TensorFlow API 数量太多，迭代太快，所以要养成随时 <a target="_blank" rel="noopener" href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf"> <em>查阅官方文档</em></a> 的习惯。</p>
<ul>
<li><code>tf.</code>：包含了张量定义，变换等常用函数和类。</li>
<li><code>tf.data</code>：输入数据处理模块，提供了像 <code>tf.data.Dataset</code> 等类用于封装输入数据，指定批量大小等。</li>
<li><code>tf.image</code>：图像处理模块，提供了像图像裁剪，变换，编码，解码等类。</li>
<li><code>tf.keras</code>：原 Keras 框架高阶 API。包含原 <code>tf.layers</code> 中高阶神经网络层。</li>
<li><code>tf.linalg</code>：线性代数模块，提供了大量线性代数计算方法和类。</li>
<li><code>tf.losses</code>：损失函数模块，用于方便神经网络定义损失函数。</li>
<li><code>tf.math</code>：数学计算模块，提供了大量数学计算函数。</li>
<li><code>tf.saved_model</code>：模型保存模块，可用于模型的保存和恢复。</li>
<li><code>tf.train</code>：提供用于训练的组件，例如优化器，学习率衰减策略等。</li>
<li><code>tf.nn</code>：提供用于构建神经网络的底层函数，以帮助实现深度神经网络各类功能层。</li>
<li><code>tf.estimator</code>：高阶 API，提供了预创建的 Estimator 或自定义组件。</li>
</ul>
<p>在构建深度神经网络时，TensorFlow 可以说提供了你一切想要的组件，从不同形状的张量、激活函数、神经网络层，到优化器、数据集等，一应俱全。</p>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/xiaohong404.github.io/tags/TensorFlow2-0/" rel="tag"><i class="fa fa-tag"></i> TensorFlow2.0</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/xiaohong404.github.io/2020/10/25/C/C%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0Linux-touch%E5%91%BD%E4%BB%A4/" rel="prev" title="C语言实现Linux-touch命令">
      <i class="fa fa-chevron-left"></i> C语言实现Linux-touch命令
    </a></div>
      <div class="post-nav-item">
    <a href="/xiaohong404.github.io/2020/10/26/TensorFlow2.0/%E5%AF%BC%E6%95%B0%E8%AE%A1%E7%AE%97%E5%92%8C%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E5%AE%9E%E7%8E%B0/" rel="next" title="导数计算和自动微分实现">
      导数计算和自动微分实现 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
  
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%A0%E9%87%8F"><span class="nav-number">1.</span> <span class="nav-text">张量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Eager-Execution"><span class="nav-number">2.</span> <span class="nav-text">Eager Execution</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86"><span class="nav-number">3.</span> <span class="nav-text">自动微分</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97"><span class="nav-number">4.</span> <span class="nav-text">常用模块</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Xiao Hong"
      src="https://avatars1.githubusercontent.com/u/69063618?s=460&u=11199d69e5551ba91c0709fae0a30a592ab1271b&v=4">
  <p class="site-author-name" itemprop="name">Xiao Hong</p>
  <div class="site-description" itemprop="description">Things always start to get better after you give up</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/xiaohong404.github.io/archives/">
        
          <span class="site-state-item-count">23</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/xiaohong404.github.io/Categories/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/xiaohong404.github.io/tags/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/xiaohong404" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;xiaohong404"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/pluto-9-55" title="ZhiHu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;pluto-9-55" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>ZhiHu</a>
      </span>
  </div>


<!-- CloudCalendar -->
<div class="widget-wrap" style="width: 90%;margin-left: auto;margin-right: auto; opacity: 0.97;">
	<div class="widget" id="CloudCalendar"></div>
</div>
      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020-10-26</span>
  <span class="with-love",id="animate">
    <i class="fa fa-basketball-ball"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xiaohong</span>
</div>


        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,0' opacity='0.5' zIndex='-1' count='150' src="/xiaohong404.github.io/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/xiaohong404.github.io/lib/anime.min.js"></script>
  <script src="/xiaohong404.github.io/lib/velocity/velocity.min.js"></script>
  <script src="/xiaohong404.github.io/lib/velocity/velocity.ui.min.js"></script>

<script src="/xiaohong404.github.io/js/utils.js"></script>

<script src="/xiaohong404.github.io/js/motion.js"></script>


<script src="/xiaohong404.github.io/js/schemes/muse.js"></script>


<script src="/xiaohong404.github.io/js/next-boot.js"></script>




  




  
<script src="/xiaohong404.github.io/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/xiaohong404.github.io/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>






  

  



  

<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'qgoG1EyC6yrAnmbPcCl9pCH8-gzGzoHsz',
      appKey     : 'yzRsxAlXtg72qlBbwrwA034j',
      placeholder: "Just go go",
      avatar     : 'wavatar',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'en,zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>


<script src="/xiaohong404.github.io/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/xiaohong404.github.io/live2dw/assets/wanko.model.json"},"display":{"position":"left","width":150,"height":300,"hOffset":80,"vOffset":-50},"mobile":{"show":true},"log":false,"tagMode":false});</script></body>
</html>
